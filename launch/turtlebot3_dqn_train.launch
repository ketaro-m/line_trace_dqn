<launch>
  <!-- parameters for learning -->
  <arg name="batch_size" default="64" doc="(int): minibatch size, or how many samples taken the replay buffer for experience replay"/>
  <arg name="gamma" default="0.995" doc="(float): discount factor (0~1)"/>
  <arg name="tau" default="1e-3" doc="for soft update of target parameters"/>
  <arg name="lr" default="0.1" doc="(float): learning rate"/>
  <arg name="update_every" default="4" doc="(int): how often to update the network"/>

  <arg name="n_episodes" default="1000" doc="(int): maximum number of training epsiodes"/>
  <arg name="max_t" default="6000" doc="(int): maximum number of timesteps per episode"/>
  <arg name="eps_start" default="1.0" doc="(float): starting value of epsilon, for epsilon-greedy action selection"/>
  <arg name="eps_end" default="0.01" doc="(float): minimum value of epsilon"/>
  <arg name="eps_decay" default="0.995" doc="(float): mutiplicative factor (per episode) for decreasing epsilon"/>

  <arg name="load_model" default="False" doc="(bool): whether load model parameters from a saved file"/>

  <node pkg="line_trace_dqn" name="dqn_train" type="dqn_train.py"
  args="--batch_size $(arg batch_size)
  --gamma $(arg gamma)
  --tau $(arg tau)
  --lr $(arg lr)
  --update_every $(arg update_every)
  --n_episodes $(arg n_episodes)
  --max_t $(arg max_t)
  --eps_start $(arg eps_start)
  --eps_end $(arg eps_end)
  --eps_decay $(arg eps_decay)
  --load_model $(arg load_model)"
  output="screen" />
</launch>